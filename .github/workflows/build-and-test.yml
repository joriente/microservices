name: Build and test

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

permissions:
  contents: read
  pull-requests: write
  checks: write

jobs:
  build:
    name: "Build" 
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - name: Cache NuGet packages
      uses: actions/cache@v4
      with:    
        path: ~/.nuget/packages
        key: ${{ runner.os }}-nuget-${{ hashFiles('**/packages.lock.json') }}    
        restore-keys: |      
          ${{ runner.os }}-nuget-

    - name: Setup .NET
      uses: actions/setup-dotnet@v4
      with:
        dotnet-version: '9.0.x'

    - name: Restore dependencies
      run: dotnet restore

    - name: Build
      run: dotnet build --no-restore --configuration Release

    - name: Upload build artifacts
      uses: actions/upload-artifact@v4
      with:
        name: build-output
        path: |
          **/bin/Release/
          **/obj/Release/
        retention-days: 1

  unit-tests:
    name: "Unit Tests"
    needs: build
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - name: Setup .NET
      uses: actions/setup-dotnet@v4
      with:
        dotnet-version: '9.0.x'

    - name: Download build artifacts
      uses: actions/download-artifact@v4
      with:
        name: build-output

    - name: Run Unit Tests with Coverage
      run: dotnet test --configuration Release --filter "FullyQualifiedName!~IntegrationTests" --logger "trx" --collect:"XPlat Code Coverage" --settings coverlet.runsettings --results-directory ./TestResults/UnitTests -- RunConfiguration.TestSessionTimeout=180000
      timeout-minutes: 5

    - name: List generated unit test files
      if: success() || failure()
      run: |
        echo "Unit test results:"
        ls -R TestResults/UnitTests/ || echo "No files found"
        echo "Searching for any coverage files:"
        find TestResults/UnitTests -type f || echo "No files at all"

    - name: Upload unit test results
      uses: actions/upload-artifact@v4
      if: success() || failure()
      with:
        name: unit-test-results
        path: TestResults/UnitTests/**/*

  integration-tests:
    name: "Integration Tests"
    needs: build
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - name: Setup .NET
      uses: actions/setup-dotnet@v4
      with:
        dotnet-version: '9.0.x'

    - name: Download build artifacts
      uses: actions/download-artifact@v4
      with:
        name: build-output

    - name: Run Integration Tests with Coverage
      continue-on-error: true
      run: dotnet test --configuration Release --filter "FullyQualifiedName~IntegrationTests" --logger "trx" --collect:"XPlat Code Coverage" --settings coverlet.runsettings --results-directory ./TestResults/IntegrationTests -- RunConfiguration.TestSessionTimeout=600000
      timeout-minutes: 15

    - name: List generated integration test files
      if: success() || failure()
      run: |
        echo "Integration test results:"
        ls -R TestResults/IntegrationTests/ || echo "No files found"
        echo "Searching for any coverage files:"
        find TestResults/IntegrationTests -type f || echo "No files at all"

    - name: Upload integration test results
      uses: actions/upload-artifact@v4
      if: success() || failure()
      with:
        name: integration-test-results
        path: TestResults/IntegrationTests/**/*

  report:
    name: "Test Report & Coverage"
    needs: [unit-tests, integration-tests]
    runs-on: ubuntu-latest
    if: always()

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Download unit test results
      uses: actions/download-artifact@v4
      with:
        name: unit-test-results
        path: TestResults/UnitTests

    - name: Download integration test results
      uses: actions/download-artifact@v4
      with:
        name: integration-test-results
        path: TestResults/IntegrationTests

    - name: List coverage files
      run: |
        echo "Searching for coverage files..."
        find TestResults -name "coverage.cobertura.xml" -type f || echo "No coverage files found"

    - name: Install ReportGenerator
      run: dotnet tool install --global dotnet-reportgenerator-globaltool

    - name: Merge Coverage Reports
      if: hashFiles('TestResults/**/coverage.cobertura.xml') != ''
      run: |
        reportgenerator \
          -reports:"TestResults/**/coverage.cobertura.xml" \
          -targetdir:"TestResults/CoverageMerged" \
          -reporttypes:"Cobertura" \
          -assemblyfilters:"-*.Tests;-*.Tests.*"
        echo "Merged coverage report created"
        ls -la TestResults/CoverageMerged/

    - name: Code Coverage Report
      uses: irongut/CodeCoverageSummary@v1.3.0
      if: hashFiles('TestResults/CoverageMerged/Cobertura.xml') != ''
      with:
        filename: 'TestResults/CoverageMerged/Cobertura.xml'
        badge: true
        fail_below_min: false
        format: markdown
        hide_branch_rate: false
        hide_complexity: false
        indicators: true
        output: both
        thresholds: '60 80'

    - name: Add Coverage PR Comment
      uses: marocchino/sticky-pull-request-comment@v2
      if: github.event_name == 'pull_request' && hashFiles('code-coverage-results.md') != ''
      with:
        recreate: true
        path: code-coverage-results.md

    - name: Unit Test Report
      uses: dorny/test-reporter@v1
      if: success() || failure()
      with:
        name: Unit Tests
        path: 'TestResults/UnitTests/**/*.trx'
        reporter: dotnet-trx
        fail-on-error: false

    - name: Integration Test Report
      uses: dorny/test-reporter@v1
      if: success() || failure()
      with:
        name: Integration Tests
        path: 'TestResults/IntegrationTests/**/*.trx'
        reporter: dotnet-trx
        fail-on-error: false

    - name: Create Test Summary
      if: github.event_name == 'pull_request' && (success() || failure())
      run: |
        echo "## ðŸ§ª Test Results Summary" > test-summary.md
        echo "" >> test-summary.md
        
        # Parse unit test results
        UNIT_PASSED=0
        UNIT_FAILED=0
        UNIT_SKIPPED=0
        for file in TestResults/UnitTests/*.trx; do
          if [ -f "$file" ]; then
            PASSED=$(grep -oP 'passed="\K[0-9]+' "$file" | head -1)
            FAILED=$(grep -oP 'failed="\K[0-9]+' "$file" | head -1)
            SKIPPED=$(grep -oP 'inconclusive="\K[0-9]+' "$file" | head -1)
            UNIT_PASSED=$((UNIT_PASSED + ${PASSED:-0}))
            UNIT_FAILED=$((UNIT_FAILED + ${FAILED:-0}))
            UNIT_SKIPPED=$((UNIT_SKIPPED + ${SKIPPED:-0}))
          fi
        done
        UNIT_TOTAL=$((UNIT_PASSED + UNIT_FAILED + UNIT_SKIPPED))
        
        echo "### âœ… Unit Tests" >> test-summary.md
        echo "| Status | Count |" >> test-summary.md
        echo "|--------|-------|" >> test-summary.md
        echo "| âœ… Passed | $UNIT_PASSED |" >> test-summary.md
        echo "| âŒ Failed | $UNIT_FAILED |" >> test-summary.md
        echo "| â­ï¸ Skipped | $UNIT_SKIPPED |" >> test-summary.md
        echo "| **Total** | **$UNIT_TOTAL** |" >> test-summary.md
        echo "" >> test-summary.md
        
        # Parse integration test results
        INT_PASSED=0
        INT_FAILED=0
        INT_SKIPPED=0
        for file in TestResults/IntegrationTests/*.trx; do
          if [ -f "$file" ]; then
            PASSED=$(grep -oP 'passed="\K[0-9]+' "$file" | head -1)
            FAILED=$(grep -oP 'failed="\K[0-9]+' "$file" | head -1)
            SKIPPED=$(grep -oP 'inconclusive="\K[0-9]+' "$file" | head -1)
            INT_PASSED=$((INT_PASSED + ${PASSED:-0}))
            INT_FAILED=$((INT_FAILED + ${FAILED:-0}))
            INT_SKIPPED=$((INT_SKIPPED + ${SKIPPED:-0}))
          fi
        done
        INT_TOTAL=$((INT_PASSED + INT_FAILED + INT_SKIPPED))
        
        echo "### ðŸ”— Integration Tests" >> test-summary.md
        echo "| Status | Count |" >> test-summary.md
        echo "|--------|-------|" >> test-summary.md
        echo "| âœ… Passed | $INT_PASSED |" >> test-summary.md
        echo "| âŒ Failed | $INT_FAILED |" >> test-summary.md
        echo "| â­ï¸ Skipped | $INT_SKIPPED |" >> test-summary.md
        echo "| **Total** | **$INT_TOTAL** |" >> test-summary.md
        echo "" >> test-summary.md
        
        # Overall summary
        TOTAL_PASSED=$((UNIT_PASSED + INT_PASSED))
        TOTAL_FAILED=$((UNIT_FAILED + INT_FAILED))
        TOTAL_SKIPPED=$((UNIT_SKIPPED + INT_SKIPPED))
        TOTAL_ALL=$((TOTAL_PASSED + TOTAL_FAILED + TOTAL_SKIPPED))
        
        echo "### ðŸ“Š Overall" >> test-summary.md
        echo "- **Total Tests**: $TOTAL_ALL" >> test-summary.md
        echo "- **Pass Rate**: $(awk "BEGIN {printf \"%.1f\", ($TOTAL_PASSED/$TOTAL_ALL)*100}")%" >> test-summary.md
        echo "" >> test-summary.md
        echo "---" >> test-summary.md
        echo "ðŸ’¡ See the **Checks** tab above for detailed test results and logs." >> test-summary.md

    - name: Add Test Summary PR Comment
      uses: marocchino/sticky-pull-request-comment@v2
      if: github.event_name == 'pull_request' && hashFiles('test-summary.md') != ''
      with:
        recreate: false
        path: test-summary.md
        header: test-results
